{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5bcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##分别进行直接聚类和降噪后聚类两种方法\n",
    "import matplotlib.image as mpimg\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import matplotlib.image as imgplt\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.utils import image_utils\n",
    "from keras import backend as K\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow\n",
    "import torch\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "\n",
    "\n",
    "# 获取图片大小和维度\n",
    "img = cv2.imread(\"/home/GaoBX/StudyRGB/1.png\")\n",
    "height, width, channels = img.shape\n",
    "print('图片大小（宽 x 高）：', width, 'x', height)\n",
    "print('图片维度（通道数）：', channels)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "##导入图片\n",
    "\n",
    "img_width, img_height, channels = 224, 224, 3\n",
    "input_shape = (img_width, img_height, channels)\n",
    "\n",
    "def load_data():\n",
    "    dir = '/home/GaoBX/StudyRGB/'\n",
    "    files = [\"%s/%s\" % (dir, x) for x in sorted(os.listdir(dir), key=lambda x: int(x.split(\".\")[0]))]\n",
    "    arr = np.empty((len(files), img_width, img_height, channels), dtype=np.float32)\n",
    "    for i, imgfile in enumerate(files):\n",
    "        img = image_utils.load_img(imgfile, target_size=(224, 224))\n",
    "        x = image_utils.img_to_array(img).reshape(img_width, img_height, channels)\n",
    "        x = x.astype('float32') / 255.\n",
    "        arr[i] = x\n",
    "    return arr\n",
    "\n",
    "X = load_data()\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "##读取细胞类别文件，一般为“meatdata”文件\n",
    "df = pd.read_csv(\"/home/GaoBX/work/metadata.csv\",index_col=0)\n",
    "true_labels = df['cluster']\n",
    "\n",
    "\n",
    "##直接聚类\n",
    "\n",
    "X = np.array(X).reshape(11227,-1)\n",
    "\n",
    "n_clusters = 6\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "ari = adjusted_rand_score(true_labels, labels)\n",
    "nmi = normalized_mutual_info_score(true_labels, labels)\n",
    "print(f\"ARI score: {ari}\")\n",
    "print(f\"NMI score: {nmi}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##降噪后聚类\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2)  # 调整张量维度以匹配PyTorch要求\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# 检查是否有可用的GPU，并将模型和数据移动到GPU上\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(8, 8, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, padding='same'),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "##AutoClass based on ResNet50\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder: Use pre-trained ResNet50 without fully connected layers\n",
    "        resnet = resnet50(pretrained=True)\n",
    "        self.encoder = nn.Sequential(*list(resnet.children())[:-2])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2048, 1024, kernel_size=2, stride=2, padding=0, output_padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2, padding=0, output_padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2, padding=0, output_padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2, padding=0, output_padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, padding=0, output_padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 创建Autoencoder模型实例\n",
    "model = Autoencoder().to(device)\n",
    "print(model)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adadelta(model.parameters())\n",
    "\n",
    "# 加载数据（请使用您的实际数据替换X）\n",
    "dataset = TensorDataset(X, X)\n",
    "data_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        # 将数据和目标移动到相同的设备（GPU或CPU）\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        output = model(data)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_function(output, target)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新权重\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印训练进度\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Step [{batch_idx}/{len(data_loader)}], Loss: {loss.item()}\")\n",
    "\n",
    "# 保存训练好的模型\n",
    "torch.save(model.state_dict(), \"autoencoder.pth\")\n",
    "\n",
    "# 定义模型\n",
    "model = Autoencoder()\n",
    "model.load_state_dict(torch.load(\"./autoencoder.pth\", map_location=device))\n",
    "\n",
    "# 将数据输入模型并得到降维后的结果\n",
    "\n",
    "result = model(X)\n",
    "result = result.detach().numpy()\n",
    "\n",
    "result\n",
    "X = X.cpu().numpy()\n",
    "\n",
    "X_encoded_reshape = result.reshape(result.shape[0], result.shape[1] * result.shape[2] * result.shape[3])\n",
    "print(X_encoded_reshape.shape)\n",
    "\n",
    "n_clusters = 6\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(X_encoded_reshape)\n",
    "labels = kmeans.labels_\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "ari = adjusted_rand_score(true_labels, labels)\n",
    "nmi = normalized_mutual_info_score(true_labels, labels)\n",
    "print(f\"ARI score: {ari}\")\n",
    "print(f\"NMI score: {nmi}\")\n",
    "\n",
    "\n",
    "\n",
    "##聚类结果二维可视化\n",
    "from sklearn.manifold import TSNE \n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, n_jobs=-1)\n",
    "##tsne_coords = tsne.fit_transform(X)\n",
    "tsne_coords = tsne.fit_transform(X_encoded_reshape)\n",
    "\n",
    "colors = {\n",
    "    0: 'maroon',\n",
    "    1: 'darkgreen',\n",
    "    2: 'darkblue',\n",
    "    3: 'teal',\n",
    "    4: 'magenta',\n",
    "    5: 'sienna',\n",
    "    6: 'olive'\n",
    "}\n",
    "fig = plt.figure()\n",
    "for i in range(len(tsne_coords)):\n",
    "    plt.scatter(tsne_coords[i, 0], tsne_coords[i, 1], color=colors[labels[i]])\n",
    "\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {i}', markerfacecolor=color, markersize=10) for i, color in colors.items()]\n",
    "legend = plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "fig.add_artist(legend)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##聚类结果三维可视化\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "#pca.fit(X)\n",
    "#total_photo_3d = pca.transform(X)\n",
    "pca.fit(X_encoded_reshape)\n",
    "total_photo_3d = pca.transform(X_encoded_reshape)\n",
    "centers = labels\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "markers = ['o', 'o', 'o', 'o', 'o', 'o', 'o']\n",
    "\n",
    "for i in range(28):\n",
    "    ax.scatter(total_photo_3d[labels == i, 0], \n",
    "               total_photo_3d[labels == i, 1], \n",
    "               total_photo_3d[labels == i, 2],\n",
    "               marker = markers[i],\n",
    "               label=f'Cluster {i+1}')\n",
    "    \n",
    "    ax.tick_params(axis='x', which='major', labelsize=12, length=4, width=1)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=12, length=4, width=1)\n",
    "    ax.tick_params(axis='z', which='major', labelsize=12, length=4, width=1)\n",
    "    \n",
    "    ax.view_init(elev=0, azim=90)\n",
    "    \n",
    "    #ax.set_xticklabels('') \n",
    "    #ax.set_yticklabels('')\n",
    "    #ax.set_zticklabels('')\n",
    "    \n",
    "fig.set_size_inches(10, 7)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
