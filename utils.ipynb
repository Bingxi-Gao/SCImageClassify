{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5573795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# build warmup lr\n",
    "def create_lr_scheduler(optimizer,\n",
    "                        num_step: int,\n",
    "                        epochs: int,\n",
    "                        warmup=True,\n",
    "                        warmup_epochs=1,\n",
    "                        warmup_factor=1e-3,\n",
    "                        end_factor=1e-6):\n",
    "    assert num_step > 0 and epochs > 0\n",
    "    if warmup is False:\n",
    "        warmup_epochs = 0\n",
    "\n",
    "    def f(x):\n",
    "        if warmup is True and x <= (warmup_epochs * num_step):\n",
    "            alpha = float(x) / (warmup_epochs * num_step)\n",
    "            return warmup_factor * (1 - alpha) + alpha\n",
    "        else:\n",
    "            current_step = (x - warmup_epochs * num_step)\n",
    "            cosine_steps = (epochs - warmup_epochs) * num_step\n",
    "            return ((1 + math.cos(current_step * math.pi / cosine_steps)) / 2) * (1 - end_factor) + end_factor\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=f)\n",
    "\n",
    "def train_one_epoch_classify(model, optimizer, data_loader, device, epoch, lr_scheduler, weight_decay):\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "    accu_num = torch.zeros(1).to(device)  # 累计预测正确的样本数\n",
    "\n",
    "    sample_num = 0\n",
    "    weight_decay = 0.0001\n",
    "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
    "    step = 0\n",
    "    for step, data in enumerate(data_loader):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images.to(device))\n",
    "        pred_classes = torch.max(pred, dim=1)[1]\n",
    "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
    "\n",
    "        loss = loss_function(pred, labels.to(device))\n",
    "\n",
    "        # 添加L2正则化\n",
    "        l2_regularization = torch.tensor(0.).to(device)\n",
    "        for param in model.parameters():\n",
    "            l2_regularization += torch.norm(param, p=2)\n",
    "\n",
    "        loss += weight_decay * l2_regularization\n",
    "\n",
    "        loss.backward()\n",
    "        accu_loss += loss.detach()\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        data_loader.desc = \"[train epoch {}] loss: {:.8f}, acc: {:.8f}, lr: {:.5f}\".format(\n",
    "            epoch,\n",
    "            accu_loss.item() / (step + 1),\n",
    "            accu_num.item() / sample_num,\n",
    "            lr\n",
    "        )\n",
    "\n",
    "        if not torch.isfinite(loss):\n",
    "            print('WARNING: 非有限损失值，结束训练 ', loss)\n",
    "            sys.exit(1)\n",
    "        optimizer.step()\n",
    "        # 更新学习率\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    return accu_loss.item() / (step + 1), accu_num.item() / sample_num, lr\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_classify(model, data_loader, device, epoch):\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    all_pred = []\n",
    "    all_prob = []\n",
    "    accu_num = torch.zeros(1).to(device)  # 累计预测正确的样本数\n",
    "    accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "    global best_acc  # 最好结果\n",
    "    sample_num = 0\n",
    "    data_loader = tqdm(data_loader, file=sys.stdout)\n",
    "    step = 0\n",
    "\n",
    "    for step, data in enumerate(data_loader):\n",
    "        images, labels = data\n",
    "        sample_num += images.shape[0]\n",
    "        pred = model(images.to(device))\n",
    "        probs = F.softmax(pred).detach().cpu().numpy()\n",
    "        data = np.around(probs, 3)\n",
    "        pred_classes = torch.max(pred, dim=1)[1].cpu()\n",
    "        accu_num += torch.eq(pred_classes, labels).sum()\n",
    "        all_pred = all_pred + np.array(pred_classes).tolist()\n",
    "        all_prob = all_prob + np.array(probs).tolist()\n",
    "        loss = loss_function(pred, labels.to(device))\n",
    "        accu_loss += loss\n",
    "\n",
    "        # val_accurate = accu_num / val_num\n",
    "        #         if val_accurate > best_acc:\n",
    "        #             print(val_accurate)\n",
    "        #             best_acc = val_accurate\n",
    "        #             torch.save(net.state_dict(), save_path)\n",
    "        data_loader.desc = \"[valid epoch {}] loss: {:.8f}, acc: {:.8f}\".format(\n",
    "            epoch,\n",
    "            accu_loss.item() / (step + 1),\n",
    "            accu_num.item() / sample_num\n",
    "        )\n",
    "    return accu_loss.item() / (step + 1), accu_num.item() / sample_num, all_pred, all_prob\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, images_path: list, images_class: list, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.images_class = images_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.images_path[item])\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert(\"RGB\")\n",
    "        #             raise ValueError(\"image: {} isn't RGB mode.\".format(self.images_path[item]))\n",
    "        label = self.images_class[item]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
    "        images, labels = tuple(zip(*batch))\n",
    "\n",
    "        images = torch.stack(images, dim=0)\n",
    "        labels = torch.as_tensor(labels)\n",
    "        return images, labels\n",
    "\n",
    "\n",
    "def kfold_split_data(root: str, k: int):\n",
    "    random.seed(1) \n",
    "    assert os.path.exists(root), \"dataset root: {} does not exist.\".format(root)\n",
    "\n",
    "    flower_class = [cla for cla in os.listdir(root) if os.path.isdir(os.path.join(root, cla))]\n",
    "    flower_class.sort()\n",
    "    class_indices = dict((k, v) for v, k in enumerate(flower_class))\n",
    "    json_str = json.dumps(dict((val, key) for key, val in class_indices.items()), indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    every_class_num = []\n",
    "    supported = [\".jpg\", \".JPG\", \".png\", \".PNG\"]\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    for cla in flower_class:\n",
    "        cla_path = os.path.join(root, cla)\n",
    "        images = [os.path.join(root, cla, i) for i in os.listdir(cla_path)\n",
    "                  if os.path.splitext(i)[-1] in supported]\n",
    "        images.sort()\n",
    "        image_class = class_indices[cla]\n",
    "        every_class_num.append(len(images))\n",
    "        all_images.extend(images)\n",
    "        all_labels.extend([image_class] * len(images))\n",
    "\n",
    "    print(\"{} images were found in the dataset.\".format(sum(every_class_num)))\n",
    "    print(\"{} images for training.\".format(len(all_images)))\n",
    "    assert len(all_images) > 0, \"number of images must be greater than 0.\"\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    dataset_splits = []\n",
    "    for train_index, val_index in kf.split(all_images):\n",
    "        train_images_path = [all_images[i] for i in train_index]\n",
    "        train_images_label = [all_labels[i] for i in train_index]\n",
    "        val_images_path = [all_images[i] for i in val_index]\n",
    "        val_images_label = [all_labels[i] for i in val_index]\n",
    "        dataset_splits.append((train_images_path, train_images_label, val_images_path, val_images_label))\n",
    "\n",
    "    return dataset_splits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
